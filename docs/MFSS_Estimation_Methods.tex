\documentclass[12pt]{article}
\usepackage{amsthm,amsfonts,mathtools,xcolor,fullpage}
\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{parskip}

\setlength{\parindent}{0pt}

\newcommand{\Gt}{G_\theta}
\newcommand{\vecop}[0]{\text{vec}}
\newcommand{\Cov}[0]{\text{Cov}}
\newcommand{\Var}[0]{\text{Var}}
\newcommand{\flag}[0]{red}
\newcommand{\tr}[0]{\text{tr}}

\newcommand{\ubar}[1]{\text{\b{$#1$}}}

\title{MFSS Estimation Methods}
\date{}
\author{}

\begin{document}

\maketitle

	This document attempts to detail how estimates of the state, the likelihood, and its gradient are calculated for a given system, and how the parameters in $\theta$ will be estimated.

	Instructions for how to set up the state space and estimate the maximum likelihood of the unknown parameters can be found in the MFSS user guide. 

\section{Kalman Filtering and Smoothing Calculations}

	We are interested in the estimate of the latent state from a state space model with time-varying parameters of the form
	\begin{align*} 
	y_t = Z_t \alpha_t + d_t + \varepsilon_t &\qquad \varepsilon_t \sim \mathcal{N}(0,H_t) \\ 
	\alpha_{t} = T_t \alpha_{t-1} + c_t + R_t \eta_t &\qquad \eta_t \sim \mathcal{N}(0, Q_t) \qquad
	\alpha_1 \sim \mathcal{N}(a_1, P_1) 
	\end{align*} 

\subsection{Multivariate Filter}
	As shown in \cite{dk_book} (\S 4.3), the filtered estimates of the state, $a_t = \mathbb{E}(\alpha_t | Y_t)$ and $P_t = \Var(\alpha_t | Y_t)$, are given by 
	\begin{align*}
	a_{t+1} = T_{t+1} a_t + c_{t+1} + K_t v_t &\qquad
	P_{t+1} = T_{t+1} P_t L_t^\prime + R_{t+1} Q_{t+1} R_{t+1}^\prime \\
	v_t = y_t - Z_ta_t - d_t &\qquad
	K_t = T_{t+1} P_t Z_t^\prime F_t^{-1} \\
	F_t = Z_t P_t Z_t^\prime + H_t &\qquad
	L_t = T_{t+1} - K_t Z_t 
	\end{align*} 

	and the smoothed estimates, $\hat{\alpha}_t = \mathbb{E}(\alpha_t | Y_n)$ and $V_t = \Var(\alpha_t | Y_n)$ are given by
	\begin{align*}
	\hat{\alpha}_t = a_t + P_t r_t &\qquad V_t = P_t - P_t N_t P_t \\ 
	r_t = Z_t^\prime F_t^{-1} v_t + L_t^\prime r_{t+1} &\qquad N_{t} = Z_t^\prime F_t^{-1} Z_t + L_t^\prime N_{t+1} L_t
	\end{align*}
	where $r_{n+1} = 0$ and $N_{n+1} = 0$. 

\subsection{Univariate Filter}
	Substantial computational gains are available using the univariate Kalman filter by avoiding the inversion of the $F_t$ matrix above (as well as enabling the use of the exact initial filter, see below). For more details, see \cite{dk_book} (\S 6.4). 

	When any $H_t$ is non-diagonal, the observation equation is transformed by taking the LDL factorization of the $H_t$ matrices. The transformed parameters are marked with $^u$ to denote that they have been transformed to be suitable for the univariate filter.
	\begin{align*}
	y_t^u = Z_t^u \alpha_t + d_t^u + \varepsilon_t^u &\qquad \varepsilon_t^u \sim N(0, H_t^u)\\
	y_t^u = C_t^{-1} y_t \qquad Z_t^u = C_t^{-1} Z_t \qquad d_t^u &= C_t^{-1} d_t \qquad \varepsilon_t^u = C_t^{-1} \varepsilon_t \qquad H_t = C_t H_t^u C_t^\prime
	\end{align*}

	The multivariate filter and smoother is then modified by computing several quantities via the univariate filter  on the transformed system: 
	\begin{align*}
	a_{t, i+1} = a_{t,i} + K_{t,i} v_{t,i} &\qquad
	 P_{t,i+1} = P_{t,i} - K_{t,i} F_{t,i} K_{t,i}^{\prime} \\
	v_{t,i} = y_{t,i} - Z_{t,i} a_{t,i} - d_{t,i} \qquad
	F_{t,i} &= Z_{t,i} P_{t,i} Z_{t,i}^\prime + H_{t,i} \qquad
	K_{t,i} = P_{t,i} Z_{t,i}^\prime F_{t,i}^{-1} \\ 
	a_{t+1,1} = T_{t+1} a_{t, p+1} + c_{t+1} &\qquad
	P_{t+1,1} = T_{t+1} P_{t,p+1} T_{t+1}^\prime + R_{t+1} Q_{t+1} R_{t+1}^\prime
	\end{align*}
	where $y_{i,t}$ is the $i$th element of $y_t^u$, $Z_{t,i}$ is the $i$th row of $Z_t^u$, $d_{t,i}$ is the $i$th element of $d_t^u$, and $H_{t,i}$ is the $i$th diagonal element of $H_t^u$. The filtered estimates of the state $a_t = a_{t,1}$ and $P_t = P_{t,1}$ are equivalent to those computed in the multivariate filter above. Note that $F_{t,i}$ is a scalar, so that $F_{t,i}^{-1}$ is simply scalar division instead of more computationally expensive matrix inversion. However, this comes at the cost of there being no convenient transformation of the quantities $v_{t,i}$, $F_{t,i}$ or $K_{t,i}$ that recovers the multivariate versions computed above.

	Similarly, the univariate smoother provides $r_t = r_{t,0}$ and $N_t = N_{t,0}$:
	\begin{align*}
	r_{t,i-1} = Z_{t,i}^\prime F_{t,i}^{-1} v_{t,i} + L_{t,i}^{\prime} r_{t,i} \qquad 
	N_{t,i-1} =& Z_{t,i}^\prime F_{t,i}^{-1} Z_{t,i} + L_{t,i}^{\prime} N_{t,i} L_{t,i} \qquad 
	L_{t,i} = I_m - K_{t,i} Z_{t,i} \\
	r_{t-1,p} = T_{t}^\prime r_{t,0} &\qquad 
	N_{t-1,p} = T_{t-1}^\prime N_{t,0} T_{t-1}
	\end{align*}
	where $r_{t+1,p} = 0$ and $N_{t+1,p} = 0$. 

\subsection{Exact Initial Kalman Filter}
	When the state $\alpha_t$ is stationary, the initial values $a_1$ and $P_1$ can be computed as the unconditional mean and variance of the state given the system parameters by inverting the transition equation. 

	To handle cases where some states are nonstationary, the state is separated into states with known variance (those that are stationary) and those that are initialized as diffuse (the nonstationary states). Let $\tilde{R}$ be a selection matrix with columns from the identity such that the initial shock $\eta_1$ is applied to the states with known variance. The selection matrix $A$ is composed of the columns of the identity matrix associated with the diffuse states such that taking the limit as $\kappa \rightarrow \infty$ allows the diffuse states to have infinite initial variance where the initial values are given by 
	\begin{align*}
	a_1 = a + \tilde{R} \eta_1 + A \delta \qquad& \eta_1 \sim N(0, \tilde{Q}) \qquad \delta \sim N(0, \kappa I) \\
	P_1 = P_{*,1} + \kappa P_{\infty,1} \qquad& P_{*,1} = \tilde{R} \tilde{Q} \tilde{R}^\prime \qquad P_{\infty,1} = A A^\prime 
	\end{align*}
	The unconditional mean, $a$, and variance, $P_{*,1}$, of the state are computed by inverting the stationary portion of the system. Any elements of $a$ associated with nonstationary or diffuse states are set to 0. Letting $\tilde{T} = \tilde{R}^\prime T_1 \tilde{R}$ and $\tilde{c} = \tilde{R}^\prime c_1$, this is accomplished by
	\begin{align*}
	\tilde{R}^\prime a &= (I_m - \tilde{T})^{-1} \tilde{c} \\
	\vecop(\tilde{R} \tilde{Q} \tilde{R}^\prime) &= (I_{m^2} - \tilde{T} \otimes \tilde{T})^{-1} \vecop(\tilde{R}^\prime R_1 Q_1 R_1^\prime \tilde{R}) 
	\end{align*}
	When all states are stationary, this initialization collapses down to the simple case where $\alpha_1 \sim N(a_1, P_1)$, where $a_1$ and $P_1$ are the unconditional mean and variance of the state, determined by inverting the full system. 

	Given this initialization, the univariate filter recursions must be altered to separate the states with finite and infinite variances (see \cite{dk_book} (\S 5.2) and \cite{dk_fast}): 
	\begin{align*}
	 F_{*,t,i} = Z_{t,i} P_{*,t,i} Z_{t,i}^\prime + H_{t,i} &\qquad F_{\infty,t,i} = Z_{t,i} P_{\infty,t,i} Z_{t,i}^\prime\\
	K_{*,t,i} = P_{*,t,i} Z_{t,i}^\prime F_{*,t,i}^{-1} &\qquad K_{\infty,t,i} = P_{\infty,t,i} Z_{t,i}^\prime F_{\infty,t,i}^{-1}
	\end{align*}
	\begin{equation*}
	a_{t,i+1} = \begin{cases} 
	      a_{t,i} + K_{*,t,i} v_{t,i} & F_{\infty,t,i} = 0 \\
	      a_{t,i} + K_{\infty,t,i} v_{t,i} & F_{\infty,t,i} \neq 0
    \end{cases} 
    \end{equation*}
	\begin{equation*}
	P_{*,t,i+1} = \begin{cases} 
	   P_{*,t,i} - K_{*,t,i} K_{*,t,i}^\prime F_{*,t,i} & F_{\infty,t,i} = 0 \\
	   P_{*,t,i} - (K_{*,t,i} K_{\infty,t,i}^\prime + K_{\infty,t,i} K_{*,t,i}^\prime - K_{\infty,t,i} K_{\infty,t,i}^\prime) F_{*,t,i} & F_{\infty,t,i} \neq 0
	\end{cases}
	\end{equation*}
	\begin{equation*}
	P_{\infty,t,i+1} = \begin{cases} 
	   P_{\infty,t,i} & F_{\infty,t,i} = 0 \\
	   P_{\infty,t,i} - K_{\infty,t,i} K_{\infty,t,i}^\prime F_{\infty,t,i} & F_{\infty,t,i} \neq 0	   
	\end{cases} 
	\end{equation*}
	\begin{align*}
	a_{t+1,1} &= T_{t+1} a_{t, p+1} + c_{t+1} \\
	P_{\infty,t+1,1} = T_{t+1} P_{\infty,t,p+1} T_{t+1}^\prime &\qquad P_{*,t+1,1} = T_{t+1} P_{*,t,p+1} T_{t+1}^\prime + R_{t+1} Q_{t+1} R_{t+1}^\prime 
	\end{align*}
	For any set of system parameters where the state can be identified, there exists some time $d$ such that $F_{\infty,d,i} = 0$ for all $i$. For time $t \geq d$, the simpler Kalman filter recursion above can be employed with $P_{t,i} = P_{*,t,i}$. 

	The smoother must be similarly altered so that beginning at $t = d$, the computation of $r_{t,i}$ is expanded to account for the initialization:
	\begin{align*}
	L_{\infty,t,i} = I_m - K_{\infty,t,i} Z_{t,i} &\qquad
	L_{*,t,i} = I_m - K_{*,t,i} Z_{t,i} \\
	L_{t,i}^{(0)} = \left(K_{\infty,t,i} - K_{*,t,i} \right) Z_{t,i} F_{*,t,i} F_{\infty,t,i}^{-1} &
	\end{align*}
	\begin{equation*}
	r_{t,i-1}^{(0)} = \begin{cases} 
	   Z_{t,i}^\prime F_{*,t,i}^{-1} v_{t,i} + L_{*,t,i}^\prime r_{t,i}^{(0)} & F_{\infty,t,i} = 0 \\
	   L_{\infty,t,i}^\prime r_{t,i}^{(0)} & F_{\infty,t,i} \neq 0	   
	\end{cases} 
	\end{equation*}
	\begin{equation*}
	r_{t,i-1}^{(1)} = \begin{cases} 
	   r_{t,i}^{(1)} & F_{\infty,t,i} = 0 \\
	   Z_{t,i}^\prime F_{\infty,t,i}^{-1} v_{t,i} + L_{t,i}^{(0)\prime} r_{t,i}^{(0)} + L_{\infty,t,i}^\prime r_{t,i}^{(1)} & F_{\infty,t,i} \neq 0	   
	\end{cases} 
	\end{equation*}
	\begin{equation*}
	r_{t-1,p}^{(0)} = T_t^\prime r_{t,0}^{(0)} \qquad r_{t-1,p}^{(1)} = T_t^\prime r_{t,0}^{(1)}  \\
	\end{equation*}
	\begin{equation*}
	\hat{\alpha}_t = a_t + P_{*,t,1} r_{t,0}^{(0)} + P_{\infty,t,1} r_{t,0}^{(1)}
	\end{equation*}
	where $r_{d,p}^{(0)} = r_{d,p}$ and $r_{d,p}^{(1)} = 0$. Note that $L_{\infty,t,i}$ and $L_{t,i}^{(0)}$ only need to be computed when $F_{\infty,t,i} \neq 0$ and $L_{*,t,i}$ only needs to be computed when $F_{\infty,t,i} = 0$. 

	For the smoothed variance of the state, 
	\begin{align*}
	V_t = P_{*,t,1} - P_{*,t,1} N_{t,0}^{(0)} P_{*,t,1} - \left(P_{\infty,t,1} N_{t,0}^{(1)} P_{*,t,1} \right)^\prime &- P_{\infty,t,1} N_{t,0}^{(1)} P_{*,t,1} - P_{\infty,t,1} N_{t,0}^{(2)} P_{\infty,t,1} \\
	N_{t-1,p}^{(0)} = T_t^\prime N_{t,0}^{(0)} T_t \qquad
	N_{t-1,p}^{(1)} = T_t^\prime N_{t,0}^{(1)} T_t &\qquad
	N_{t-1,p}^{(2)} = T_t^\prime N_{t,0}^{(1)} T_t 
	\end{align*}
	where when $F_{\infty,t,i} = 0$, 
	\begin{align*}
	N_{t,i-1}^{(0)} = Z_{t,i}^\prime F_{*,t,i}^{-1} Z_{t,i} + L_{*,t,i}^\prime N_{t,i}^{(0)} L_{*,t,i} &\qquad
	N_{t,i-1}^{(1)} = N_{t,i}^{(1)} &\qquad
	N_{t,i-1}^{(2)} = N_{t,i}^{(2)} 
	\end{align*}
	and when $F_{\infty,t,i} \neq 0$,
	\begin{align*}
	N_{t,i-1}^{(0)} &= L_{\infty,t,i}^\prime N_{t,i}^{(0)} L_{\infty,t,i}\\
	N_{t,i-1}^{(1)} &= Z_{t,i}^{*\prime} F_{\infty,t,i}^{-1} Z_{t,i} + L_{\infty,t,i}^\prime N_{t,i}^{(0)} L_{t,i}^{(0)} + L_{\infty,t,i}^\prime N_{t,i}^{(1)} L_{\infty,t,i}  \\
	N_{t,i-1}^{(2)} &= Z_{t,i}^\prime F_{\infty,t,i}^{-2} Z_{t,i} F_{*,t,i} + L_{t,i}^{(0)\prime} N_{t,i}^{(1)} L_{t,i}^{(0)} + L_{\infty,t,i}^\prime N_{t,i}^{(1)} L_{t,i}^{(0)} + L_{t,i}^{(0)\prime} N_{t,i}^{(1)} L_{\infty,t,i} + L_{\infty,t,i}^\prime N_{t,i}^{(2)} L_{\infty,t,i}
	\end{align*}
	where $N_{d,p}^{(0)} = N_{d,p}$ and $N_{d,p}^{(1)} = N_{d,p}^{(2)} = 0$. 

% \subsubsection*{Other definitions}
% 	\begin{align*}
% 	{\color{\flag} u_t = F_t^{-1} v_t + K_t^\prime r_t} &\qquad 
% 	{\color{\flag} D_t = F_t^{-1} K_t^\prime N_t K_t} \\
% 	\hat{\eta_t} = Q_t R_t^\prime r_t &\qquad \Var(\eta_t | Y_n) = Q_t - Q_t R_t^\prime N_t R_t Q_t \\
% 	J_t = \Cov(\alpha_{t+1}, \alpha_t | Y_n) &= P_t L_t (I_m - N_t P_{t+1})
% 	\end{align*}

% \newpage

\section{State Decompositions}
	
	\label{sec:state_decompositions}
	Since all of the Kalman filter and smoother calculations are linear, we can decompose the estimated states by the effects of the data and parameters on each states. In general, we will be creating a four-dimensional object since each state $k \in \{1, \dots, m\}$ at time $t$ is affected by data series $i \in \{1, \dots, p\}$ from time $j$. Depending on the use of the decompositions, this 4D object will be collapsed in different ways. For example, if we were suspicious of the validity of an observation, we could inspect how much it affects a state variable of interest, in which case we could select a particular $j$, $k$, and $i$ and plot across $t$. More commonly we will be interested in plots of how a given state variable is determined by the data, in which case we sum across the origin dates of the data $j$ and plot the effect of each data series on a given state $i$ across time $t$. 

	\subsection{Filtered State Decompositions}
	For the filter, we are interested in 
	\begin{align*}
	a_t =  \omega_t^{a_0} + \omega_{tt}^c  + \sum_{j=1}^{t-1} \left( \omega_{tj}^c + \omega_{tj}^d + \omega_{tj} \right) 
	\end{align*}
	where 
	\begin{itemize}
		\item $\omega_t^{a_0}$ is an $(m \times m)$ matrix of the effect of the initial conditions on $a_t$, 
		\item $\omega_{tj}^c$ is an $(m \times m)$ matrix of the effect of $c_j$ on $a_t$, 
		\item$\omega_{tj}^d$ is an $(m \times p)$ matrix of the effect of $d_j$ on $a_t$, and 
		\item $\omega_{tj}$ is an $(m \times p)$ matrix of the effect of $y_j$ on $a_t$. 
	\end{itemize}
	In each case, the period of the state being affected is denoted by $t$ and the period of the observation of parameter causing the effect is denoted by $j$. 

	We begin by incorporating the observed data from a single period. Using the filtering equations from above, we examine the integration of information contained in $y_t$ on $a_{t+1} = a_{t+1,1}$ given $a_{t,1}$:
	\begin{align*}
	a_{t,2} &= a_{t,1} + K_{t,1} v_{t,1} \\
			&= a_{t,1} + K_{t,1} (y_{t,1} - Z_{t,1} a_{t,1} - d_{t,1}) \\
			&= L_{t,1} a_{t,1} + K_{t,1} (y_{t,1} - d_{t,1}) \\
	a_{t,3} &= a_{t,2} + K_{t,2} v_{t,2} \\
			&= a_{t,2} + K_{t,2} (y_{t,2} - Z_{t,2} a_{t,2} - d_{t,2}) \\
			&= L_{t,2} (L_{t,1} a_{t,1} + K_{t,1} (y_{t,1} - d_{t,1})) + K_{t,2} (y_{t,2} - d_{t,2}) \\
			&= L_{t,2} L_{t,1} a_{t,1} + K_{t,2} (y_{t,2} - d_{t,2}) + L_{t,2} K_{t,1} (y_{t,1} - d_{t,1}) \\
			&\vdots \\
	a_{t,p+1} &= \left(\prod_{k=p}^1 L_{t,k} \right) a_{t,1} + \sum_{i=1}^p \left(\prod_{k=p}^{i+1} L_{t,k} \right) K_{t,i} (y_{t,i} - d_{t,i}) \\
	a_{t+1,1} &= T_{t+1} a_{t,p+1} + c_{t+1} \\
		&= T_{t+1} \left(\prod_{k=p}^1 L_{t,k} \right) a_{t,1} 
			 + c_{t+1}
			 + T_{t+1} \sum_{i=1}^p \left(\prod_{k=p}^{i+1} L_{t,k} \right) K_{t,i} y_{t,i} 
			 - T_{t+1} \sum_{i=1}^p \left(\prod_{k=p}^{i+1} L_{t,k} \right) K_{t,i} d_{t,i} \\
		&= L_t^* a_{t,1} + c_{t+1} + K_t^* y_t - K_t^* d_t 
	\end{align*}
	where the products over $L_{t,k}$ proceed from higher to lower values of $k$ and 
	\begin{align*}
	L_t^\dagger = T_{t+1} \prod_{i=p}^1 L_{t,i} & \qquad & 
	K_t^\dagger = T_{t+1} \begin{bmatrix} \left(\prod_{i=p}^{2} L_{t,i} \right) K_{t,1} &  \dots & L_{t,p} K_{t,p-1} & K_{t,p} \end{bmatrix}
	\end{align*}
	
	% From this result, we can write the univariate filter substantially like the multivariate filter: 
	% \begin{align*}
	% a_{t+1} = M_{t+1} a_t + c_{t+1} + K_t^* y_t  - K_t^* d_t &\qquad
	% P_{t+1} = T_{t+1} P_t L_t^{*\prime} + R_{t+1} Q_{t+1} R_{t+1}^\prime \qquad \\
	% &\qquad
	% F_{t,i} = Z_{t,i} P_{t,i} Z_{t,i}^\prime + H_{t,i} \\
	% K_{t,i} = P_{t,i} Z_{t,i}^\prime F_{t,i}^{-1} &\qquad
	% K_t^* = T_{t+1} \begin{bmatrix} \left(\prod_{i=p}^{2} L_{t,i} \right) K_{t,1} &  \dots & L_{t,p} K_{t,p-1} & K_{t,p} \end{bmatrix} \\
	% L_{t,i} = I_m - K_{t,i} Z_{t,i} &\qquad
	% L_{t+1} = T_{t+1} \prod_{i=p}^1 L_{t,i} 
	% \end{align*}

	To find find how information propagates across time, we use this new formulation of the filter, starting with the first period:
	\begin{align*}
	a_1 =& L_0^* a_0 + c_1 \\
	a_2 =& L_1^* a_1 + c_2 + K_1^* y_1 - K_1^*  d_1 \\
		=& L_1^*(L_0^* a_0 + c_1) + c_2 + K_1^* y_1 - K_1^* d_1 \\
		=& L_1^* L_0^* a_0 + L_1^* c_1 + c_2 + K_1^* y_1 - K_1^* d_1 \\
	a_3 =& L_2^* a_2 + c_3 + K_2^* y_2 - K_2^* d_2 \\
		=& L_2^* L_1^* L_0^* a_0 + L_2^* L_1^* c_1 + L_2^* c_2 + c_3 + L_2^* K_1^* y_1  + K_2^* y_2 - L_2^* K_1^* d_1 - K_2^* d_2 
	\end{align*}
	From which the recursion becomes clear and we can see that information propagates with the product of the $L_t^*$ matrix. 

	When using the univariate treatment of multivariate series, each series $i$ in $y_{t,i}$ can potentially affect each transformed series $y_{t,i}^*$. To take this into account, we must repeatedly consider the effects of a full vector of observables where each series $y_{t,i}$ is considered in turn. To do so, we can simply consider the product $C_t^{-1} \text{diag}(y_t)$, which gives us the full contribution from $y_{t,i}$ across all transformed series $y_{t,i}^*$. 

	To accommodate the exact initialization, allow for the slight abuse of notation such that 
	\begin{align*}
	K_{t,i} = \begin{dcases}
		K_{*,t,i} & F_{\infty,t,i} = 0 \\ 
		K_{\infty,t,i} & F_{\infty,t,i} \neq 0
	\end{dcases}
	\end{align*}
	which allows the earlier definitions of $K_t^*$ and $L_t^*$ to hold.
	
	From the above expressions, we can infer that the weights are 
	\begin{align*}
	\omega_{tj} &= \left( \prod_{\tau=t-1}^{j+1} L_\tau^* \right) K_j^* C_j^{-1} \text{diag}(y_j) & \qquad 	
	\omega_{tj}^c &= \left( \prod_{\tau=t-1}^{j} L_\tau^* \right) \text{ diag} (c_j) \\ 
	\omega_{tj}^d &= -\left( \prod_{\tau=t-1}^{j+1} L_\tau^* \right) K_j^* C_j^{-1} \text{diag}(d_j) & \qquad	
	\omega_t^{a_0} &= \left( \prod_{\tau=t-1}^0 L_\tau^* \right) \text{ diag} (a_0)
	\end{align*}
	completing the earlier desired decomposition of the filtered state. 

	\subsection{Smoothed State Decompositions}
	\newcommand\omegar{\stackrel{r}{\omega}}
	\newcommand\omegarzero{\stackrel{r^{(0)}}{\omega}}
	\newcommand\omegarone{\stackrel{r^{(1)}}{\omega}}




	For the smoother, we similarly want to compute quantities $\{\hat{\omega}_{tj}, \hat{\omega}_t^c, \hat{\omega}_t^d, \hat{\omega}_t^{a_0}\}$ such that 
	\begin{align*}
	\hat{\alpha}_t = \hat{\omega}_t^{a_0} + \sum_{j=1}^{T} \left( \hat{\omega}_{tj} + \hat{\omega}_{tj}^c + \hat{\omega}_{tj}^d \right)
	\end{align*}

	% By writing out the smoother recursion with $T = 3$, 
	% \begin{align*}
	% \hat{\alpha}_3 =& a_3 + P_3 r_3 \\
	% 	=& a_3 + P_3 Z_3^\prime F_3^{-1} v_3 \\
	% 	=& a_3 + P_3 Z_3^\prime F_3^{-1} (y_3 - Z_3 a_3 - d_3) \\
	% 	=& [I - P_3 Z_3^\prime F_3^{-1} Z_3] a_3 + P_3 Z_3^\prime F_3^{-1} y_3 - P_3 Z_3^\prime F_3^{-1} d_3 \\
	% 	=& [I - P_3 N_3] \left[L_2 L_1 L_0 a_0 + L_2 L_1 c_1 + L_2 c_2 + c_3 + L_2 K_1 y_1  + K_2 y_2 - L_2 K_1 d_1 - K_2 d_2 \right] \\ 
	% 		\quad& + P_3 Z_3^\prime F_3^{-1} y_3 - P_3 Z_3^\prime F_3^{-1} d_3 \\
	% \hat{\alpha}_2 =& a_2 + P_2 r_2 \\
	% 	=& a_2+ P_2 Z_2^\prime F_2^{-1} (y_2 - Z_2 a_2 - d_2) + P_2 L_2^\prime Z_3^\prime F_3^{-1} (y_3 - Z_3 a_3 - d_3)  \\
	% 	=& [I - P_2 Z_2^\prime F_2^{-1} Z_2] a_2 -P_2 L_2^\prime Z_3^\prime F_3^{-1} Z_3 a_3\\
	% 		\quad& + P_2 Z_2^\prime F_2^{-1} y_2 + P_2 L_2^\prime Z_3 F_3^{-1} y_3 - P_2 Z_2^\prime F_2^{-1} d_2 - P_2 L_2^\prime Z_3 F_3^{-1} d_3 \\
	% 	=& [I - P_2 N_2] [L_1 L_0 a_0 + L_1 c_1 + c_2] - P_2 L_2^\prime Z_3^\prime F_3^{-1} Z_3 c_3 \\
	% 	\quad& + [I - P_2 N_2] K_1 y_1 + P_2 [Z_2^\prime F_2^{-1} - L_2^\prime N_3 K_2] y_2 + P_2 L_2 Z_3^\prime F_3^{-1} y_3 \\
	% 	\quad& - [I - P_2 N_2] K_1 d_1 - P_2 [Z_2^\prime F_2^{-1} - L_2^\prime N_3 K_2] d_2  - P_2 L_2 Z_3^\prime F_3^{-1} d_3 \\
	% \hat{\alpha}_1 =& a_1 + P_1 r_1 \\ 
	% 	=& a_1 P_1 (Z_1^\prime F_1^{-1} v_1 + L_1^\prime Z_2^\prime F_2^{-1} v_2 + L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} v_3) \\
	% 	=& a_1 + P_1 Z_1^\prime F_1^{-1} (y_1 - Z_1 a_1 - d_1) + P_1 L_1^\prime Z_2^\prime F_2^{-1} (y_2 - Z_2 a_2 - d_2) + P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} (y_3 - Z_3 a_3 - d_3) \\
	% 	=& [I - P_1 Z_1^\prime F_1^{-1} Z_1] a_1 + P_1 Z_1^\prime F_1^{-1} y_1 - P_1 Z_1^\prime F_1^{-1} d_1 \\
	% 	\quad& + P_1 L_1^\prime Z_2^\prime F_2^{-1} y_2 - P_1 L_1^\prime Z_2^\prime F_2^{-1} Z_2 a_2 - P_1 L_1^\prime Z_2^\prime F_2^{-1} d_2 \\
	% 	\quad& + P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} y_3 - P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} Z_3 a_3 - P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} d_3 \\
	% 	=& [I - P_1 N_1] (L_0 a_0 + c_1) - P_1 L_1^\prime N_2 c_2 - P_1 L_1^\prime L_2^\prime N_3 c_3  \\
	% 	\quad& + P_1 [Z_1^\prime F_1^{-1} - L_1^\prime N_2 K_1] y_1 + P_1 L_1^\prime [Z_2^\prime F_2^{-1} - L_2^\prime N_3 K_2] y_2 + P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} y_3 \\
	% 	\quad& - P_1 [Z_1^\prime F_1^{-1} - L_1^\prime N_2 K_1] d_1 - P_1 L_1^\prime [Z_2^\prime F_2^{-1} - L_2^\prime N_3 K_2] d_2 - P_1 L_1^\prime L_2^\prime Z_3^\prime F_3^{-1} d_3
	% \end{align*}

	% From this we can infer that 
	% \begin{align*}
	% \hat{\omega}_{tj} &= \begin{dcases}
	% 	[I - P_j N_j] \left(\prod_{i=t-1}^{j+1} L_i \right) K_j & t > j \\
	% 	P_t \left(\prod_{i=t}^{j-1} L_i^\prime \right) [Z_j^\prime F_j^{-1} - L_j^\prime N_{j+1} K_j] & t \leq j
	% \end{dcases} \\
	% \hat{\omega}_{tj}^d &= \begin{dcases}
	% 	- [I - P_j N_j] \left(\prod_{i=t-1}^{j-1} L_i \right) K_j d_j & t > j \\
	% 	- P_t \left(\prod_{i=t}^{j-1} L_i^\prime \right) [Z_j^\prime F_j^{-1} - L_j^\prime N_{j+1} K_j] d_j & t \leq j
	% \end{dcases} \\
	% \hat{\omega}_{tj}^c &= \begin{dcases} 
	% 	[I - P_j N_j] \left(\prod_{i=t-1}^j L_i \right) c_j & t \geq j  \\
	% 	- P_t \left(\prod_{i=t}^{j-1} L_i^\prime \right) N_j c_j & t < j\\
	% \end{dcases} \\
	% \hat{\omega}_t^{a_0} &= [I - P_t N_t] \left(\prod_{i=t-1}^{0} L_i \right) a_0 
	% \end{align*}
	% Note that the conditions for $\hat{\omega}_{tj}^c$ is different than the others due to how information was incorporated in the filter. 



	We first begin by breaking this expression into contributions from $a_t$ and $r_t$,  
	\begin{align*}
	r_t &= \omegar_t^{a_0} + \sum_{j=t}^{T} \left( \omegar_{tj}^c + \omegar_{tj}^d + \omegar_{tj} \right) \\
	\hat{\alpha}_t &= a_t + P_t r_t \\
		&= \omega_t^{a_0} + P_t \omegar_t^{a_0} + \sum_{j=1}^{T} \left( \omega_{tj}^c + P_t \omegar_{tj}^c + \omega_{tj}^d + P_t \omegar_{tj}^d + \omega_{tj} + P_t \omegar_{tj} \right)  \\
		&= \hat{\omega}_t^{a_0} + \sum_{j=1}^{T} \left( \hat{\omega}_{tj}^c + \hat{\omega}_{tj}^d + \hat{\omega}_{tj} \right)
	\end{align*}
	where
	\begin{align*}
	\hat{\omega}_{tj} &= \omega_{tj} + P_t \omegar_{tj} &\quad \hat{\omega}_{tj}^c &= \omega_{tj}^c + P_t \omegar_{tj}^c &\quad
	 \hat{\omega}_{tj}^d &= \omega_{tj}^d + P_t \omegar_{tj}^d &\quad \hat{\omega}_t^{a_0} &= \omega_t^{a_0} + P_t \omegar_t^{a_0} 
	\end{align*}
	
	Before examining the smoother recursion, we first rewrite the observation errors in matrix form, 
	\begin{align*}
	v_t^u &= \begin{bmatrix}
	y_{t,1} - Z_{t,1} a_{t,1} - d_{t,1}\\
	y_{t,2} - Z_{t,2} a_{t,2} - d_{t,2} \\
	y_{t,3} - Z_{t,3} a_{t,3} - d_{t,3} \\
	\vdots \\
	y_{t,p} - Z_{t,p} a_{t,p} - d_{t,p}
	\end{bmatrix} \\
	&= y_t^u - d_t^u - \begin{bmatrix}
	Z_{t,1} a_{t,1} \\
	Z_{t,2} [L_{t,1} a_{t,1} + K_{t,1} (y_{t,1} - d_{t,1})] \\
	Z_{t,3} [L_{t,2} L_{t,1} a_{t,1} + L_{t,2} K_{t,1} (y_{t,1} - d_{t,1}) + K_{t,2} (y_{t,2} - d_{t,2})] \\
	\vdots \\
	Z_{t,p} \left[\left(\prod_{k=p-1}^1 L_{t,k} \right) a_{t,1} + \sum_{i=1}^{p-1} \left(\prod_{k=p-1}^{i+1} L_{t,k} \right) K_{t,i} (y_{t,i} - d_{t,i}) \right]
	\end{bmatrix} \\
	&= y_t^u - d_t^u - \tilde{A}_t^y (y_t^u - d_t^u) - A_t^a a_t \\
	&= A_t^y C_t^{-1} (y_t - d_t) - A_t^a a_t
	\end{align*}
	where $A_t^y = I_p - \tilde{A}_t^y$ and 
	\begin{align*}
	\tilde{A}_t^y &= \begin{bmatrix}
	0 & 0 & \dots & 0 & 0 & 0 \\
	Z_{t,2} K_{t,1} & 0 & \dots & 0 & 0 & 0\\
	Z_{t,3} L_{t,2} K_{t,1} & Z_{t,3} K_{t,2} & \dots & 0 & 0 & 0  \\
	\vdots & \vdots &  & \vdots & \vdots & \vdots \\
	Z_{t,p-1} (\prod_{k=p-2}^2 L_{t,k}) K_{t,1} & Z_{t,p-1} (\prod_{k=p-2}^3 L_{t,k}) K_{t,2} & \dots & Z_{t,p-1} K_{t,p-2} & 0 & 0 \\
	Z_{t,p} (\prod_{k=p-1}^2 L_{t,k}) K_{t,1} & Z_{t,p} (\prod_{k=p-1}^3 L_{t,k}) K_{t,2} & \dots & Z_{t,p} L_{t,p-1} K_{p-2} & Z_{t,p} K_{t,p-1} & 0
	\end{bmatrix} \\
	A_t^a &= \begin{bmatrix}
	Z_{t,1} \\
	Z_{t,2} L_{t,1} \\
	\vdots \\
	Z_{t,p} \left(\prod_{k=p-1}^1 L_{t,k} \right) 
	\end{bmatrix}
	\end{align*}
	For the diffuse filter, this must be altered so that the lower-diagonal elements of $A_t^y$ instead depend on the condition on $F_{\infty,t,i}$ and the propogation of $a_{t,0}$ respects the selection between $L_{*,t,i}$ and $L_{\infty,t,i}$:
	\begin{align*}
	{A_t^y}_{(i,j)} = \begin{dcases}
	-Z_{t,i} \left(\prod_{k=i-1}^j S_{t,k}^* \right) K_{*,t,j}  &  F_{\infty,t,j} = 0 \\
	-Z_{t,i} \left(\prod_{k=i-1}^j S_{t,k}^* \right) K_{\infty,t,j}  & F_{\infty,t,j} \neq 0 
	\end{dcases}
	&\qquad
	A_t^{a*} = \begin{bmatrix}
	Z_{t,1} \\
	Z_{t,2} S_{t,2}^* \\
	\vdots \\
	Z_{t,p} \left(\prod_{k=p-1}^1 S_{t,k}^* \right) 
	\end{bmatrix} 
	\end{align*}

	Similarly to how $a_t$ was handled for the filter, the incorporation of the information at time $t$ to form $r_{t,0}$ given $r_{t+1,0}$ can be written as a single operation in matrix for as
	\begin{align*}
	r_{t,p} &= T_{t+1}^\prime r_{t+1,0} \\
	r_{t,p-1} &= Z_{t,p}^\prime F_{t,p}^{-1} v_{t,p} + L_{t,p}^\prime T_{t+1}^\prime r_{t+1,0} \\
	r_{t,p-2} &= Z_{t,p-1}^\prime F_{t,p-1}^{-1} v_{t,p-1} + L_{t,p-1}^\prime r_{t,p-1} \\
		&= Z_{t,p-1}^\prime F_{t,p-1}^{-1} v_{t,p-1} + L_{t,p-1}^\prime Z_{t,p}^\prime F_{t,p}^{-1} v_{t,p} + L_{t,p-1}^\prime L_{t,p}^\prime T_{t+1}^\prime r_{t+1,0} \\ 
		&\vdots \\
	r_{t,0} &= M_t^\dagger v_t^u + L_t^{\dagger\prime} r_{t+1,0} \\
			&= M_t^\dagger A_t^y C_t^{-1} y_t - M_t^\dagger A_t^y C_t^{-1} d_t - M_t^\dagger A_t^a a_t + L_t^{\dagger\prime} r_{t+1,0}
	\end{align*}
	where 
	\begin{align*}
	M_t^\dagger &= \begin{bmatrix} Z_{t,1}^\prime F_{t,1}^{-1} &  L_{t,1}^\prime Z_{t,2}^\prime F_{t,2}^{-1} & \dots & \left(\prod_{i=1}^{p-1} L_{t,i}^\prime \right)  Z_{t,p}^\prime F_{t,p}^{-1} \end{bmatrix} \\
	&= A_t^{a\prime} \text{diag}\left( \begin{bmatrix} F_{t,1}^{-1} &  F_{t,2}^{-1} & \dots &  F_{t,p}^{-1} \end{bmatrix}  \right)
	\end{align*}

	Noting the similarity between propagation through time like $a_t$, we have that 
	\begin{align*}
	\omegar_{tj} &= L_t^{\dagger\prime} \omegar_{t+1,j} - \left\{ M_t^\dagger A_t^a  \omega_{tj} \right\}_{t>j} + \left\{M_t^\dagger A_t^y C_t^{-1} \text{ diag} (y_t) \right\}_{t=j} \\
	\omegar_{tj}^d &= L_t^{\dagger\prime} \omegar_{t+1,j}^d - \left\{ M_t^\dagger A_t^a \omega_{tj}^d \right\}_{t>j} - \left\{M_t^\dagger A_t^y C_t^{-1} \text{ diag} (d_t) \right\}_{t=j} \\
	\omegar_{tj}^c &= L_t^{\dagger\prime} \omegar_{t+1,j}^c - \left\{ M_t^\dagger A_t^a \omega_{tj}^c \right\}_{t \geq j} \\
	\omegar_{t}^{a_0} &= L_t^{\dagger\prime} \omegar_{t+1}^{a_0} - M_t^\dagger A_t^a \omega_{t}^{a_0} 
	\end{align*}

	To accommodate the exact initialization, we expand $r_t$ as as done in the smoother: 
	\begin{align*}
	\hat{\alpha}_t &= a_t + P_{*,t,1} r_{t,0}^{(0)} + P_{\infty,t,1} r_{t,0}^{(1)}
	\end{align*}
	where
	\begin{align*}
	r_{t,i-1}^{(0)} &= \begin{dcases} 
	   Z_{t,i}^\prime F_{*,t,i}^{-1} v_{t,i} + L_{*,t,i}^\prime r_{t,i}^{(0)} & F_{\infty,t,i} = 0 \\
	   L_{\infty,t,i}^\prime r_{t,i}^{(0)} & F_{\infty,t,i} \neq 0	   
	\end{dcases} \\
	r_{t,i-1}^{(1)} &= \begin{dcases} 
	   r_{t,i}^{(1)} & F_{\infty,t,i} = 0 \\
	   Z_{t,i}^\prime F_{\infty,t,i}^{-1} v_{t,i} + L_{\infty,t,i}^\prime r_{t,i}^{(1)} + L_{t,i}^{(0)\prime} r_{t,i}^{(0)} & F_{\infty,t,i} \neq 0	   
	\end{dcases} 
	\end{align*}

	To handle the selection in these equations based on the condition $F_{\infty,t,i} = 0$, define a set of selection quantities: 
	\begin{align*}
	S_{t,i}^* &= \begin{dcases}
		L_{*,t,i} & F_{\infty,t,i} = 0 \\
		L_{\infty,t,i} & F_{\infty,t,i} \neq 0
	\end{dcases} &\quad
	S_{t,i}^\infty &= \begin{dcases}
		I_m & F_{\infty,t,i} = 0 \\
		L_{\infty,t,i} & F_{\infty,t,i} \neq 0
	\end{dcases} &\quad
	S_{t,i}^{(0)} &= \begin{dcases}
		0_{m \times m} & F_{\infty,t,i} = 0 \\
		L_{t,i}^{(0)} & F_{\infty,t,i} \neq 0
	\end{dcases} 
	\end{align*}
	\begin{align*}
	M_{t,i}^* &= \begin{dcases}
		Z_{t,1}^\prime F_{*,t,1}^{-1} & F_{\infty,t,i} = 0 \\
		0_{m \times 1} & F_{\infty,t,i} \neq 0 
	\end{dcases} &\quad
	M_{t,i}^\infty &= \begin{dcases}
		0_{m \times 1} & F_{\infty,t,i} = 0 \\
		Z_{t,1}^\prime F_{\infty,t,1}^{-1} & F_{\infty,t,i} \neq 0
	\end{dcases} 
	\end{align*}
	This allows the recursion of the diffuse smoother to be written as 
	\begin{align*}
	r_{t,i-1}^{(0)} &= M_{t,i}^* v_{t,i} + S_{t,i}^{*\prime} r_{t,i}^{(0)} &\quad
	r_{t,i-1}^{(1)} &= M_{t,i}^\infty v_{t,i} +  S_{t,i}^{\infty\prime} r_{t,i}^{(1)} + S_{t,i}^{(0)\prime} r_{t,i}^{(0)}
	\end{align*}
	Using these quantities, we can rewrite the recursion for $r_{t,0}^{(0)}$ as we did $r_{t,0}$. To arrive at the similar recursion for $r_{t,0}^{(1)}$, first make the simplifcations that were done for $r_{t,0}$:
	\begin{align*}
	r_{t,0}^{(1)} = \tilde{M}_t^\infty v_t^u + L_t^{\infty\prime} r_{t+1,0}^{(1)} + \sum_{i=1}^p \left(\prod_{k=1}^{i-1} S_{t,k}^{\infty\prime} \right) S_{t,i}^{(0)\prime} r_{t,i}^{(0)}
	\end{align*}
	Also note that we can infer from the manipulation of $r_{t,0}$ earlier that 
	\begin{align*}
	r_{t,i} = \left(\prod_{k=i+1}^p L_{t,k}^\prime \right) T_{t+1}^\prime r_{t+1,0} + \sum_{j=i+1}^p \left(\prod_{k=i+1}^{j-1} L_{t,k}^\prime \right) Z_{t,j}^\prime F_{t,j}^{-1} v_{t,j}
	\end{align*}
	Making the required notation adjustments, these two equations give the recursion
	\begin{align*}
	r_{t,0}^{(1)} &= \tilde{M}_t^\infty v_t^u + L_t^{\infty\prime} r_{t+1,0}^{(1)} \\
	&\quad + \sum_{i=1}^p \left(\prod_{k=1}^{i-1} S_{t,k}^{\infty\prime} \right) S_{t,i}^{(0)\prime} \left(\prod_{k=i+1}^p S_{t,k}^{*\prime} \right) T_{t+1}^\prime r_{t+1,0}^{(0)} \\
	&\quad + \sum_{i=1}^p \left(\prod_{k=1}^{i-1} S_{t,k}^{\infty\prime} \right) S_{t,i}^{(0)\prime} \sum_{j=i+1}^p \left(\prod_{k=i+1}^{j-1} S_{t,k}^{*\prime} \right) M_{t,j}^* v_{t,j} \\
	&= (\tilde{M}_t^\infty + M_t^{(0)}) v_t^u + L_t^{(0)\prime} r_{t+1,0}^{(0)} + L_t^{\infty\prime} r_{t+1,0}^{(1)} 
	\end{align*}
	
	This allows us to write the recursions required for the diffuse smoother as
	\begin{align*}
	r_{t,0}^{(0)} &= M_t^* v_t^u + L_t^{*\prime} r_{t+1,0}^{(0)} &\quad
	r_{t,0}^{(1)} &= M_t^\infty v_t^u + L_t^{(0)\prime} r_{t+1,0}^{(0)} + L_t^{\infty\prime} r_{t+1,0}^{(1)} 
	\end{align*}
	%where 
	\begin{align*}
	L_t^* &= T_{t+1} \left(\prod_{i=p}^1 S_{t,i}^* \right) &\quad
	L_t^\infty &= T_{t+1} \left(\prod_{i=p}^1 S_{t,i}^\infty \right) &\quad 
	L_t^{(0)} &= T_{t+1} \left[ \sum_{i=1}^p \left(\prod_{k=1}^{i-1} S_{t,k}^{\infty\prime} \right) S_{t,i}^{(0)\prime} \left(\prod_{k=i+1}^p S_{t,k}^{*\prime} \right) \right]^\prime
	\end{align*}
	\begin{align*}
	M_t^* &= \begin{bmatrix} M_{t,1}^* &  S_{t,1}^{*\prime} M_{t,2}^* & \dots & \left(\prod_{i=1}^{p-1} S_{t,i}^{*\prime} \right)  M_{t,p}^* \end{bmatrix} &\quad
	M_t^\infty &= \tilde{M}_t^\infty + M_t^{(0)} \\
	\tilde{M}_t^\infty &= \begin{bmatrix} M_{t,1}^\infty &  S_{t,1}^{\infty\prime} M_{t,2}^\infty & \dots & \left(\prod_{i=1}^{p-1} S_{t,i}^{\infty\prime} \right)  M_{t,p}^\infty \end{bmatrix} &\quad
	M_t^{(0)} &= \sum_{i=1}^p \left(\prod_{k=1}^{i-1} S_{t,k}^{\infty\prime} \right) S_{t,i}^{(0)\prime} M_{t,i}^{(0)} 
	\end{align*}
	\begin{align*}
	M_{t,i}^{(0)} &= \begin{bmatrix} 0 & \dots & 0 & M_{t,i+1}^* & S_{t,i+1}^{*\prime} M_{t,i+2}^* & \dots & \left(\prod_{k=i+1}^{p-1} S_{t,k}^{*\prime} \right) M_{t,p}^* \end{bmatrix} 
	\end{align*}
	
	Combined with the expressions above gives the recusion
	\begin{align*}
	r_{t,0}^{(0)} &= M_t^* A_t^y C_t^{-1} y_t - M_t^* A_t^y C_t^{-1} d_t - M_t^* A_t^a a_t + L_t^{*\prime} r_{t+1,0}^{(0)} \\
	r_{t,0}^{(1)} &= M_t^\infty A_t^y C_t^{-1} y_t - M_t^\infty A_t^y C_t^{-1} d_t - M_t^\infty A_t^a a_t + L_t^{(0)\prime} r_{t+1,0}^{(0)} + L_t^{\infty\prime} r_{t+1,0}^{(1)} 
	\end{align*}
	from which the weights for the diffuse smoother are similar to above
	\begin{align*}
	\omegarzero_{tj} &= L_t^{*\prime} \omegarzero_{t+1,j} - \left\{ M_t^* A_t^a \omega_{tj} \right\}_{t>j} + \left\{M_t^* A_t^y C_t^{-1} \text{ diag} (y_t) \right\}_{t=j} \\
	\omegarzero_{tj}^d &= L_t^{*\prime} \omegarzero_{t+1,j}^d - \left\{ M_t^* A_t^a \omega_{tj}^d \right\}_{t>j} - \left\{M_t^* A_t^y C_t^{-1} \text{ diag} (d_t) \right\}_{t=j} \\
	\omegarzero_{tj}^c &= L_t^{*\prime} \omegarzero_{t+1,j}^c - \left\{ M_t^* A_t^a \omega_{tj}^c \right\}_{t \geq j} \\
	\omegarzero_{tj}^{a_0} &= L_t^{*\prime} \omegarzero_{t+1}^{a_0} - M_t^* A_t^a \omega_{t}^{a_0} \\
	\omegarone_{tj} &= L_t^{\infty\prime} \omegarone_{t+1,j} - \left\{ M_t^\infty A_t^a \omega_{tj} \right\}_{t>j} + \left\{M_t^\infty A_t^y C_t^{-1} \text{ diag} (y_t) \right\}_{t=j} + L_t^{(0)} \omegarzero_{t+1,j} \\
	\omegarone_{tj}^d &= L_t^{\infty\prime} \omegarone_{t+1,j}^d - \left\{ M_t^\infty A_t^a \omega_{tj}^d \right\}_{t>j} - \left\{M_t^\infty A_t^y C_t^{-1} \text{ diag} (d_t) \right\}_{t=j} + L_t^{(0)} \omegarzero_{t+1,j}^d \\
	\omegarone_{tj}^c &= L_t^{\infty\prime} \omegarone_{t+1,j}^c - \left\{ M_t^\infty A_t^a \omega_{tj}^c \right\}_{t \geq j} + L_t^{(0)} \omegarzero_{t+1,j}^c \\
	\omegarone_{t}^{a_0} &= L_t^{\infty\prime} \omegarone_{t+1}^{a_0} - M_t^\infty A_t^a \omega_{t}^{a_0} + L_t^{(0)} \omegarzero_{t+1}^{a_0}
	\end{align*}

	These can then be used similarly to those above to find weights for $\alpha_t$ for $t \leq d$:
	\begin{align*}
	\hat{\omega}_{tj} &= \omega_{tj} + P_t^* \omegarzero_{tj} + P_t^\infty \omegarone_{tj} &\quad 
	\hat{\omega}_{tj}^c &= \omega_{tj}^c + P_t^* \omegarzero_{tj}^c + P_t^\infty \omegarone_{tj}^c\\
	 \hat{\omega}_{tj}^d &= \omega_{tj}^d + P_t^* \omegarzero_{tj}^d + P_t^\infty \omegarone_{tj}^d &\quad 
	 \hat{\omega}_t^{a_0} &= \omega_t^{a_0} + P_t^* \omegarzero_t^{a_0}  + P_t^\infty \omegarone_t^{a_0} 
	\end{align*}
	
	% Using the fact that $v_{t,i}$ can also be written as 
	% \begin{align*}
	% v_{t,i} &= y_{t,i} - Z_{t,i} a_{t,i} - d_{t,i} \\ 
	% 		&= y_{t,i} - Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) a_{t,1} - d_{t,i}
	% \end{align*}
	% we can rewrite the smoother recursion equation as 
	% \begin{align*}
	% r_{t,p} &= T_{t+1}^\prime r_{t+1,0} \\
	% r_{t,p-1} &= Z_{t,p}^\prime F_{t,p}^{-1} v_{t,p} + L_{t,p}^\prime T_{t+1}^\prime r_{t+1,0} \\
	% r_{t,p-2} &= Z_{t,p-1}^\prime F_{t,p-1}^{-1} v_{t,p-1} 
	% 			+ L_{t,p-1}^\prime Z_{t,p}^\prime F_{t,p}^{-1} v_{t,p} 
	% 			+ L_{t,p-1}^\prime L_{t,p}^\prime T_{t+1}^\prime r_{t+1,0} \\
	% 		&\vdots \\
	% r_{t,0} &= \sum_{i=1}^p \left(\prod_{k=i}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} v_{t,i} + \left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime r_{t+1,0} \\
	% 		&= \sum_{i=1}^p \left(\prod_{k=i}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} \left[y_{t,i} - Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) a_{t,1} - d_{t,i} \right] + \left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime r_{t+1,0} 
	% \end{align*}

	
	% Because we have already decomposed $a_{t,1}$, we can use the quantities computed above to decompose $r_t$. Remember that in cases where $t \leq j$, the contribution of the data $j$ to the state at time $t$ is zero, $\omega_{t,j,i} = 0$ (intuitively, this is because the effects of any data have been included in the filtered state $a_t$). Similarly, $c_t$ doesn't show up in any of the expressions below because the direct effects have already been incorporated into the filtered states and will be found in $\omega_{t,j,i}^c$.

	% We then have 
	% \begin{align*}
	% \omegar_{t,j,i} &= \begin{dcases}
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1,j,i} - \sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) \omega_{t,j,i} & t > j \\
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1,j,i} + \sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} y_{t,i} & t = j \\
	% 	 \left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1,j,i} & t < j
	% \end{dcases} \\
	% \omegar_{tj}^d &= \begin{dcases}
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^d - \sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) \omega_{t,j,i}^d  & t > j \\
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^d - \sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} d_{t,i} & t = j \\
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^d & t < j 
	% \end{dcases} \\
	% \omegar_{tj}^c &= \begin{dcases} 
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^c -\sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1} Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) \omega_{t,j,i}^c  & t \geq j + 1 \\
	% 	\left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^c & t < j + 1
	% \end{dcases} \\
	% \omegar_{t}^{a_0} &= \left(\prod_{k=1}^p L_{t,k}^\prime \right) T_{t+1}^\prime \omegar_{t+1}^{a_0} - \sum_{i=1}^p \left(\prod_{k=1}^{i-1} L_{t,k}^\prime \right) Z_{t,i}^\prime F_{t,i}^{-1}Z_{t,i} \left(\prod_{k=i-1}^1 L_{t,k} \right) \omega_t^{a_0} 
	% \end{align*}
	% which can then be used in the earlier expressions for $\{\hat{\omega}_{t,j,i}, \hat{\omega}_{tj}^c, \hat{\omega}_{tj}^d, \hat{\omega}_t^{a_0}\}$. 

	% \subsection{State Decompositions when using the Exact Initialization}
	

	% \newcommand\omegarZero{\stackrel{r^{(0)}}{\omega}}
	% \newcommand\omegarOne{\stackrel{r^{(1)}}{\omega}}

	% For the smoothed states, the expansion of $r_{t,i}$ must be taken into account, for which we will construct weights for $r_{t,i}^{(0)}$ and $r_{t,i}^{(1)}$ similar to that above, that is
	% \begin{align*}
	% r_t^{(0)} &= \omegarZero_t^{a_0} + \sum_{j=t}^{T} \left( \omegarZero_{tj}^c + \omegarZero_{tj}^d + \sum_{i=1}^p \omegarZero_{t,j,i} y_{j,i} \right) \\
	% r_t^{(1)} &= \omegarOne_t^{a_0} + \sum_{j=t}^{T} \left( \omegarOne_{tj}^c + \omegarOne_{tj}^d + \sum_{i=1}^p \omegarOne_{t,j,i} y_{j,i} \right) \\
	% \hat{\alpha}_t &= a_t + P_{*,t,1} r_{t,0}^{(0)} + P_{\infty,t,1} r_{t,0}^{(1)} \\
	% 		&= \hat{\omega}_t^{a_0} + \sum_{j=1}^{T} \left( \hat{\omega}_{tj}^c + \hat{\omega}_{tj}^d + \sum_{i=1}^p \hat{\omega}_{t,j,i} y_{j,i} \right)
	% \end{align*}
	% where
	% \begin{align*}
	% \hat{\omega}_{t,j,i} &= \omega_{t,j,i} + P_{*,t,1} \omegarZero_{t,j,i} + P_{\infty,t,1} \omegarOne_{t,j,i} &\quad \hat{\omega}_{tj}^c &= \omega_{tj}^c + P_{*,t,1} \omegarZero_{tj}^c + P_{\infty,t,1} \omegarOne_{tj}^c \\\
	%  \hat{\omega}_{tj}^d &= \omega_{tj}^d + P_{*,t,1} \omegarZero_{tj}^d  + P_{\infty,t,1} \omegarOne_{tj}^d &\quad \hat{\omega}_t^{a_0} &= \omega_t^{a_0} + P_{*,t,1} \omegarZero_t^{a_0} + P_{\infty,t,1} \omegarOne_t^{a_0}
	% \end{align*}
	%  The construction of weights for $r_{t,i}^{(0)}$ is symmetric to the weights for $r_{t,i}$ where $L_{t,i}$ selects between $L_{*,t,i}$ and $L_{\infty,t,i}$ based on $F_{\infty,t,i}$ and the term for $v_{t,i}$ is dropped when $F_{\infty,t,i} \neq 0$. 

\section{Likelihood Calculation}
	The likelihood of of data $y_1, \dots, y_n$ in the standard filter as shown in \cite{dk_book} (\S 7.2) is given by the prediction error decomposition:
	\begin{equation*}
	\log L(Y_n) = -\frac{np}{2} \log 2\pi - \frac{1}{2} \sum_{t=1}^n \left(\log |F_t| + v_t^\prime F_{t,i}^{-1} v_t \right)
	\end{equation*}
	
	For the univariate filter, the same decomposition works in the univariate context:
	\begin{equation} \label{eq:likelihood_uni}
	\log L(Y_n) = -\frac{np}{2} \log 2\pi - \frac{1}{2} \sum_{t=1}^n \sum_{i=1}^p\log F_{t,i}+ v_{t,i}^2 / F_{t,i} 
	\end{equation}
	
	The likelihood for the exact initial filter allows for some simplifications in $F_{\infty,t,i}$ as shown in \cite{dk_book} (\S 7.2):
	\begin{equation} \label{eq:likelihood_uni_diff}
	\log L_d(Y_n) = -\frac{1}{2} \sum_{t=1}^n \sum_{i=1}^p \iota_{t,i} \log 2\pi  - \frac{1}{2}  \sum_{t=1}^d \sum_{i=1}^p w_{t,i} - \frac{1}{2} \sum_{t=d}^n \sum_{i=1}^p \iota_{t,i} \left(\log F_{t,i}+ v_{t,i}^2 / F_{t,i} \right)
	\end{equation}
	where  $\iota_{t,i} = 1$ if $F_{*,t,i} \neq 0$ or $ t > d$, and 
	\begin{equation*}
	w_{t,i} = \begin{cases} 
	   \iota_{t,i} (\log (F_{*,t,i}) + v_{t,i}^{(0)2} / F_{*,t,i}) & F_{\infty,t,i} = 0 \\
	   \log F_{\infty,t,i} & F_{\infty,t,i} \neq 0
	\end{cases} 
	\end{equation*}
	Since these quantities are naturally produced by the Kalman filter, this is the preferred method to calculate the likelihood.

\section{Parameter Estimation}
	\label{sec:parameter_estimation}

	The elements of the parameter matrices $Z_t$, $d_t$, $H_t$, $T_t$, $c_t$, $R_t$, and $Q_t$ are divided into those that are known and those that are to be estimated as a function of the parameter vector $\theta$. We are interested in the maximum likelihood estimate of those parameters given data $Y_n = \{y_1, \dots, y_n\}$. 

	We are interested in the maximum likelihood estimate of a set of \emph{structural parameters} ($\theta$) given data $y_1, \dots, y_n$ where elements of the \emph{state space parameters} ($Z_t$, $d_t$, $H_t$, $T_t$, $c_t$, $R_t$, and $Q_t$) depend on $\theta$. For simplicity, the state space parameters will be restricted such that each of their scalar elements must be a function of a single element of a vector of the \emph{reduced form parameters} ($\psi$) which depend on $\theta$. The reduced form parameters are unrestricted in how they may depend on $\theta$, allowing for a rich specification of parameter restrictions. In many estimations, there will be the same number of structural parameters and reduced form parameters. 

	More formally, let $\theta^U \in \mathbb{R}^{n_\theta}$ and $\psi \in \mathbb{R}^{n_\psi}$ where $n_\theta \leq n_\psi$. Define a set of bounds $\ubar{\theta}$  and $\bar{\theta}$ such that each element $\theta_i$ of $\theta \in \mathbb{R}^{n_\theta}$, $\ubar{\theta}_i \leq \theta_i \leq \bar{\theta}_i$. 
	Define a set of functions $\Psi_i: [\ubar{\theta}, \bar{\theta}] \rightarrow \mathbb{R}$ such that each element of $\psi$ is a function of the structural parameters, $\psi_i = \Psi_i(\theta)$. Except in cases of cross-parameter restrictions, $n_\theta = n_\psi$ and $\Psi_i(\theta) = \theta_i$ so that $\psi = \theta$. In cases of cross-parameter restrictions, the user must define the $\Psi_i$ functions for each restricted element. Also, unless initial values will be given as the vector $\theta$ (which is occasionally inconvenient), the inverse function $\Psi^{-1} : \mathbb{R}^{n_\psi} \rightarrow \mathbb{R}^{n_\theta}$ must also be specified.

	Additionally define a set of functions $\tau_{X_{i,j}}: \mathbb{R} \rightarrow \mathbb{R}$ for $X \in \{ Z_t, d_t, H_t, T_t, c_t, R_t, Q_t \}$ such that each element of the parameter matrices to be estimated is a transformation of an element of $\psi$. Common $\tau_{X_{i,j}}$ transformations include the identity, exponential, negative exponential, and logistic transformations to allow for an unbounded $\psi \in \mathbb{R}^{n_\psi}$ while maintaining bounds on the parameter matrices. When estimating models with mixed-frequency data, all state space parameters shared between the high-frequency and low-frequency states depend on the same reduced form parameters simply by using different $\tau_{X_{i,j}}$ functions. In almost all cases, the specification of the $\tau_{X_{i,j}}$ functions will be done automatically to account for state space parameter bounds and accumulator definitions. User definitions of $\tau_{X_{i,j}}$ should be rare. 

	With the likelihood of an unconstrained parameter vector $\theta^U$ defined, the optimization can be performed using common gradient ascent methods available in the Matlab Optimization Toolbox. In practice, it has been observed that further improvements in the likelihood are possible using simplex based optimization methods the gradient ascent method has converged. Due to this, the two methods are repeated until neither is able to improve the likelihood using standard convergence criteria. 

\appendix
\newpage

\section{Analytic Gradient}
\subsection{Matrix Derivatives}
	\label{sec:gradient_derivation}
	Denote $\partial \left[ \vecop(A)^\prime \right] / \partial \theta$ by $\Gt(A)$, where for an $m \times n$ matrix $A$ and a $\theta$ of length $n_\theta$, $\Gt(A)$ will be a $n_\theta \times mn$ matrix of partial derivatives. Several identities from \cite{nagakura} are needed in computing the gradient (assume matrices are of dimensions such that the expression on the left-hand side exists):

	\begin{enumerate}[label=(\alph*)]
	\item \label{gradID:sum} $\Gt(A + B) = \Gt(A) + \Gt(B)$
	\item \label{gradID:mult} $\Gt(A B) = \Gt(A) (B \otimes I_{p_A}) + \Gt(B)(I_{q_B} \otimes A^\prime)$
	\item \label{gradID:trans} $\Gt(A^\prime) = \Gt(A) K_{p_A q_A}$ 
	\item \label{gradID:quad} $\Gt(ACA^\prime) = \Gt(A)(CA^\prime \otimes I_{p_A}) N_{p_A} + \Gt(C)(A^\prime \otimes A^\prime)$
	\item \label{gradID:inv} $\Gt(D^{-1}) = -\Gt(D)(D^{-1} \otimes D^{\prime-1})$ 
	\item \label{gradID:logdet} $\Gt(\log |D|) = \Gt(D) \text{ vec} (D^{\prime-1})$
	\end{enumerate}
	where $C$ is symmetric, $D$ is nonsingular, $K_{mn}$ is a commutation matrix of size $mn$, and $N_m = I_{m^2} + K_{mm}$. For any given matrix $M$ is of dimension $p_M \times q_M$. Note that $\Gt(AA^\prime)$ can easily be computed from \ref{gradID:quad} by treating $C$ as the identity matrix. Also note that $A \otimes I_1 = A$ and $\log |B| = \log B$ if $B$ is a scalar. 

	The chain rule for the operator $\Gt(\cdot)$ is simply $\Gt(A) = \Gt(\psi) G_\psi(A)$ where $A$ is a function of $\psi$ which is a function of $\theta$. This can be shown by noting that 
	\begin{equation*}
	\frac{\partial A_{i,j}}{\partial \theta_k} = \sum_{l = 1}^{n_\psi} \frac{\partial A_{i,j}}{\partial \psi_l} \frac{\partial \psi_l}{\partial \theta_k}
	\end{equation*}
	which defines the appropriate element of the matrix product $\Gt(\psi)G_\psi(A)$.

\subsection{Univariate Gradient}
	Following the notation of \cite{nagakura}, we denote $\partial \left[ \vecop(A)^\prime \right] / \partial \theta$ by $\Gt(A)$, where for an $m \times n$ matrix $A$ and a $\theta$ of length $n_\theta$, $\Gt(A)$ will be a $n_\theta \times mn$ matrix of partial derivatives. See Appendix \ref{sec:gradient_derivation} for details and properties of $\Gt(\cdot)$. For the calculation of the gradients of the state space parameters, see section \ref{sec:parameter_estimation}.

	% The gradient of Equation \ref{eq:likelihood_uni} with respect to $\theta$ is then given by: 
	% \begin{equation} \label{eq:gradient_uni}
	% \Gt(\log L(Y_n)) = -\frac{1}{2} \sum_{t=1}^{n} \sum_{i=1}^{p} \Gt(F_{t,i}) \left[F_{t,i}^{-1} - v_{t,i}^2 F_{t.i}^{-2}\right] + 2 \Gt(v_{t,i}) F_{t,i}^{-1} v_{t,i} 
	% \end{equation}
	% where 
	% \begin{align*}
	% \Gt(v_{t,i}) &= - \Gt(Z_{t,i}) a_{t,i} - \Gt(a_{t,i}) Z_{t,i} - \Gt(d_{t,i}) \\ 
	% \Gt(F_{t,i}) &= \Gt(Z_{t,i}) (P_{t,i} Z_{t,i}^\prime) N_m + \Gt(P_{t,i}) (Z_{t,i}^\prime \otimes Z_{t,i}^\prime) + \Gt(H_{t,i})
	% \end{align*}
	% where $\Gt(a_{t,i})$ and $\Gt(P_{t,i})$ are given by the recursion 
	% \begin{align*}
	% \Gt(a_{t,i+1}) &= \Gt(a_{t,i}) + \Gt(K_{t,i}) (v_{t,i} \otimes I_m) + \Gt(v_{t,i}) K_{t,i}^\prime \\
	% \Gt(a_{t+1,1}) &= \Gt(T_{t+1})(a_{t,p+1} \otimes I_m) + \Gt(a_{t,p+1}) T_{t+1}^\prime + \Gt(c_{t+1}) \\
	% \Gt(P_{t,i+1}) &= \Gt(P_{t,i}) - \Gt(K_{t,i})(F_{t,i} K_{t,i}^\prime \otimes I_m) - \Gt(F_{t,i}) (K_{t,i}^\prime \otimes K_{t,i}^\prime) \\
	% \Gt(P_{t+1,1}) &= \Gt(T_{t+1}) (P_{t,p+1} T_{t+1}^\prime \otimes) N_m + \Gt(P_{t,p+1}) (T_{t+1}^\prime \otimes T_{t+1}^\prime) \\
	% &\quad + \Gt(R_{t+1}) (Q_{t+1} R_{t+1}^\prime \otimes I_m) N_m + \Gt(Q_{t+1})(R_{t+1}^\prime \otimes R_{t+1}^\prime) \\
	% \Gt(K_{t,i}) &= \left[ \Gt(P_{t,i}) (Z_{t,i}^\prime \otimes I_m) + \Gt(Z_{t,i}) K_{1m} P_{t,i} \right] F_{t,i}^{-1} - \Gt(F_{t,i}) F_{t,i}^{-2} P_{t,i} Z_{t,i}
	% \end{align*}
	% where $\Gt(a_{0,1}) = \Gt(a_0)$ and $\Gt(P_{0,1}) = \Gt(P_0)$, which are given below. See Appendix \ref{sec:gradient_derivation} for details. 

	Given the univariate likelihood function \eqref{eq:likelihood_uni}, the identities for the gradient in Appendix \ref{sec:gradient_derivation} produce the expression for the univariate gradient: 
	\begin{align*}
	\Gt(\log L(Y_n)) &= \Gt \left(-\frac{np}{2} \log 2\pi - \frac{1}{2} \sum_{t=1}^n \sum_{i=1}^p \log F_{t,i}+ v_{t,i}^2 F_{t,i}^{-1}\right) \\
	&= -\frac{1}{2} \sum_{t=1}^n \sum_{i=1}^p \Gt(\log F_{t,i}) + \Gt(v_{t,i}^2 F_{t,i}^{-1}) \\
	&= - \sum_{t=1}^n \sum_{i=1}^p \frac{1}{2}  \Gt(F_{t,i}) \left[F_{t,i}^{-1} - F_{t,i}^{-2} v_{t,i}^2\right] +  \Gt(v_{t,i}) F_{t,i}^{-1} v_{t,i}
	\end{align*}
	The quantities used in the gradient recursion are computed similarly using the definitions from the univariate filter: 
	\begin{align*}
	\Gt(v_{t,i}) &= \Gt(y_{t,i} - Z_{t,i} a_{t,i} - d_{t,i}) \\
	&= \Gt(y_{t,i}) -\Gt(Z_{t,i}) a_{t,i} - \Gt(a_{t,i}) Z_{t,i}^\prime - \Gt(d_{t,i}) \\
	\Gt(F_{t,i}) &= \Gt(Z_{t,i} P_{t,i} Z_{t,i}^\prime + H_{t,i}) \\
	&= 2 \Gt(Z_{t,i})P_{t,i} Z_{t,i}^\prime + \Gt(P_{t,i}) (Z_{t,i}^\prime \otimes Z_{t,i}^\prime) + \Gt(H_{t,i}) \\
	\Gt(K_{t,i}) &= \Gt(P_{t,i} Z_{t,i}^\prime F_{t,i}^{-1}) \\
	&= \Gt(P_{t,i} Z_{t,i}^\prime) F_{t,i}^{-1} + \Gt(F_{t,i}^{-1}) Z_{t,i} P_{t,i} \\
	&= \Gt(P_{t,i}) (Z_{t,i}^\prime F_{t,i}^{-1} \otimes I_m) + \Gt(Z_{t,i}) P_{t,i} F_{t,i}^{-1} - \Gt(F_{t,i}) F_{t,i}^{-2} Z_{t,i} P_{t,i} \\
	\Gt(a_{t+1,1}) &= \Gt(T_{t+1} a_{t,p+1} + c_{t+1}) \\
	&= \Gt(T_{t+1}) (a_{t,p+1} \otimes I_m) + \Gt(a_{t,p+1}) T_{t+1}^\prime + \Gt(c_{t+1})\\ 
	\Gt(a_{t,i+1}) &= \Gt(a_{t,i} + K_{t,i} v_{t,i}) \\	
	&= \Gt(a_{t,i}) + \Gt(K_{t,i})v_{t,i} + \Gt(v_{t,i})K_{t,i}^\prime \\
	\Gt(P_{t+1,1}) &= \Gt(T_{t+1} P_{t,p+1} T_{t+1}^\prime + R_{t+1} Q_{t+1} R_{t+1}^\prime) \\
	&= \Gt(T_{t+1})(P_{t,p+1} T_{t+1}^\prime \otimes I_m) N_m + \Gt(P_{t,p+1})(T_{t+1}^\prime \otimes T_{t+1}^\prime) \\
	&\quad + \Gt(R_{t+1})(Q_{t+1} R_{t+1}^\prime \otimes I_m) N_m + \Gt(Q_{t+1})(R_{t+1}^\prime \otimes R_{t+1}^\prime) \\
	\Gt(P_{t,i+1}) &= \Gt(P_{t,i} - K_{t,i} F_{t,i} K_{t,i}^\prime) \\ 
	&= \Gt(P_{t,i}) - \Gt(K_{t,i})(F_{t,i}K_{t,i}^\prime \otimes I_m) N_m - \Gt(F_{t,i})(K_{t,i}^\prime \otimes K_{t,i}^\prime)
	\end{align*}
	where $N_m = I_{m^2} + K_{mm}$ for a commutation matrix $K_{mm}$. The initial period gradients $\Gt(a_{1,1}) = \Gt(a_1)$ and $\Gt(P_{1,1}) = \Gt(P_1)$ will be given below. The values of $\Gt(y_{t,i})$ are computed according to 
	\begin{align*}
	\Gt(y_t^*) &= \Gt(C_t^{-1} y_t) \\
	&= -\Gt(C_t) (C_t^{-1} \otimes C_t^{\prime-1}) (y_t \otimes I_p)
	\end{align*}
	where $\Gt(y_{t,i})$ is the $i$th column of $\Gt(y_t^*)$.

\subsection{Exact Initial Gradient}
	The process for computing the gradient for use with the exact initial filter is similar. Throughout, it is assumed that the boolean outcome of the tests $F_{*,t,i} = 0$ or $F_{\infty,t,i} = 0$ are unaffected by changes to $\theta$. Beginning with the likelihood function, 	
	\begin{align*}
	\Gt(\log L_d(Y_n)) &= \Gt\left(-\frac{1}{2} \sum_{t=1}^n \sum_{i=1}^p \iota_{t,i} \log 2\pi  - \frac{1}{2}  \sum_{t=1}^d \sum_{i=1}^p w_{t,i} - \frac{1}{2} \sum_{t=d}^n \sum_{i=1}^p \iota_{t,i} \left(\log F_{t,i}+ v_{t,i}^2 / F_{t,i} \right) \right)\\
	&= - \frac{1}{2}  \sum_{t=1}^d \sum_{i=1}^p \Gt(w_{t,i}) -\frac{1}{2} \sum_{t=d}^n \sum_{i=1}^p \Gt(F_{t,i}) \left[F_{t,i}^{-1} - F_{t,i}^{-2} v_{t,i}^2\right] + 2 \Gt(v_{t,i}) F_{t,i}^{-1} v_{t,i}
	\end{align*}
	where 
	\begin{align*}
	\Gt(w_{t,i}) &= \begin{cases} 
	   \Gt(\iota_{t,i} (\log (F_{*,t,i}) + v_{t,i}^{(0)2} / F_{*,t,i})) & F_{\infty,t,i} = 0 \\
	   \Gt(\log F_{\infty,t,i}) & F_{\infty,t,i} \neq 0
	\end{cases} \\
	 &= \begin{cases} 
	   \iota_{t,i} \Gt(F_{*,t,i}) \left[F_{*,t,i}^{-1} - F_{*,t,i}^{-2} v_{t,i}^{(0)2}\right] +  \iota_{t,i} 2 \Gt(v_{t,i}^{(0)}) F_{*,t,i}^{-1} v_{t,i}^{(0)} & F_{\infty,t,i} = 0 \\
	   \Gt(F_{\infty,t,i}) F_{\infty,t,i}^{-1}  & F_{\infty,t,i} \neq 0
	\end{cases} 
	\end{align*}

	The required quantities in the recursion come from the definition of the filter and are similar to the basic univariate definitions: 
	\begin{align*}
	\Gt(F_{*,t,i}) &= \Gt(Z_{t,i} P_{*,t,i} Z_{t,i}^\prime + H_{t,i}) \\
	&= 2 \Gt(Z_{t,i})P_{*,t,i} Z_{t,i}^\prime + \Gt(P_{*,t,i}) (Z_{t,i}^\prime \otimes Z_{t,i}^\prime) + \Gt(H_{t,i}) \\
	\Gt(F_{\infty,t,i}) &= \Gt(Z_{t,i} P_{\infty,t,i} Z_{t,i}^\prime) \\
	&= 2 \Gt(Z_{t,i})P_{\infty,t,i} Z_{t,i}^\prime + \Gt(P_{\infty,t,i}) (Z_{t,i}^\prime \otimes Z_{t,i}^\prime)  \\
	\Gt(K_{*,t,i}) &= \Gt(P_{*,t,i} Z_{t,i}^\prime F_{*,t,i}^{-1}) \\
	&= \Gt(P_{*,t,i}) (Z_{t,i}^\prime F_{*,t,i}^{-1} \otimes I_m) + \Gt(Z_{t,i}) P_{*,t,i} F_{*,t,i}^{-1} - \Gt(F_{*,t,i}) F_{*,t,i}^{-2} Z_{t,i} P_{*,t,i}\\
	\Gt(K_{\infty,t,i}) &= \Gt(P_{\infty,t,i} Z_{t,i}^\prime F_{\infty,t,i}^{-1}) \\
	&= \Gt(P_{\infty,t,i}) (Z_{t,i}^\prime F_{\infty,t,i}^{-1} \otimes I_m) + \Gt(Z_{t,i}) P_{\infty,t,i} F_{\infty,t,i}^{-1} - \Gt(F_{\infty,t,i}) F_{\infty,t,i}^{-2} Z_{t,i} P_{\infty,t,i}
	\end{align*}

	Between periods, 
	\begin{align*}
	\Gt(a_{t+1,1}) &= \Gt(T_{t+1} a_{t,p+1} + c_{t+1}) \\
	&= \Gt(T_{t+1}) (a_{t,p+1} \otimes I_m) + \Gt(a_{t,p+1}) T_{t+1}^\prime + \Gt(c_{t+1})\\ 
	\Gt(P_{*,t+1,1}) &= \Gt(T_{t+1} P_{*,t,p+1} T_{t+1}^\prime + R_{t+1} Q_{t+1} R_{t+1}^\prime) \\
	&= \Gt(T_{t+1})(P_{*,t,p+1} T_{t+1}^\prime \otimes I_m) N_m + \Gt(P_{*,t,p+1})(T_{t+1}^\prime \otimes T_{t+1}^\prime) \\
	&\quad + \Gt(R_{t+1})(Q_{t+1} R_{t+1}^\prime \otimes I_m) N_m + \Gt(Q_{t+1})(R_{t+1}^\prime \otimes R_{t+1}^\prime) \\
	\Gt(P_{\infty,t+1,1}) &= \Gt(T_{t+1} P_{\infty,t,p+1} T_{t+1}^\prime) \\
	&= \Gt(T_{t+1})(P_{\infty,t,p+1} T_{t+1}^\prime \otimes I_m) N_m + \Gt(P_{\infty,t,p+1})(T_{t+1}^\prime \otimes T_{t+1}^\prime)
	\end{align*}

	When $F_{\infty,t,i} = 0$, 
	\begin{align*}
	\Gt(a_{t,i+1}) &= \Gt(a_{t,i} + K_{*,t,i} v_{t,i}) \\
	&= \Gt(a_{t,i}) + \Gt(K_{*,t,i})v_{t,i} + \Gt(v_{t,i}) K_{*,t,i}^{\prime}  \\
	\Gt(P_{*,t,i}) &= \Gt(P_{*,t,i} - K_{*,t,i} K_{*,t,i}^\prime F_{*,t,i}) \\
	&= \Gt(P_{*,t,i}) - \Gt(K_{*,t,i})(F_{*,t,i}K_{*,t,i}^\prime \otimes I_m) N_m - \Gt(F_{*,t,i})(K_{*,t,i}^\prime \otimes K_{*,t,i}^\prime) \\
	\Gt(P_{\infty,t,i+1}) &= \Gt(P_{\infty,t,i}) 
	\end{align*}

	and when $F_{\infty,t,i} \neq 0$, 
	\begin{align*}
	\Gt(a_{t,i+1}) &= \Gt(a_{t,i} + K_{\infty,t,i} v_{t,i}) \\
	&= \Gt(a_{t,i}) + \Gt(K_{\infty,t,i})v_{t,i} + \Gt(v_{t,i}) K_{\infty,t,i}^\prime  \\
	\Gt(P_{*,t,i+1}) &= \Gt \left(P_{*,t,i} - (K_{*,t,i} K_{\infty,t,i}^\prime + K_{\infty,t,i} K_{*,t,i}^\prime - K_{\infty,t,i} K_{\infty,t,i}^\prime) F_{*,t,i} \right) \\
	&= \Gt(P_{*,t,i}) - \Gt (F_{*,t,i}) (K_{*,t,i} K_{\infty,t,i}^\prime + K_{\infty,t,i} K_{*,t,i}^\prime - K_{\infty,t,i} K_{\infty,t,i}^\prime) \\
	& \quad - \Gt(K_{*,t,i}) (K_{\infty,t,i} \otimes I_m) N_m F_{*,t,i}\\
	& \quad - \Gt(K_{\infty,t,i}) [(K_{*,t,i} - K_{\infty,t,i}^\prime) \otimes I_m] N_m F_{*,t,i}\\
	\Gt(P_{\infty,t,i+1}) &= \Gt(P_{\infty,t,i} - K_{\infty,t,i} K_{\infty,t,i}^\prime F_{\infty,t,i}) \\
	&= \Gt(P_{\infty,t,i}) - \Gt(K_{\infty,t,i})(F_{\infty,t,i} K_{\infty,t,i}^\prime \otimes I_m) N_m - \Gt(F_{\infty,t,i}) (K_{\infty,t,i}^\prime \otimes K_{\infty,t,i}^\prime) \\
	\end{align*}

\subsection{Initial Conditions}
	The initial conditions for the recursion are given via the expressions for $a_1$ and $P_1$. We assume that the rank of $A$ and $R_0$ are not affected by $\theta$: 
	\begin{align*}
	\Gt(a_1) &= \Gt(a) + \Gt(R_0 \eta_0) + \Gt(A \delta) = \Gt(a) \\
	\Gt(P_1) &= \Gt(\tilde{R} \tilde{Q} \tilde{R}) + \Gt(\kappa A A^\prime) = \Gt(\tilde{R} \tilde{Q} \tilde{R})\\
	% &= \Gt(\tilde{Q})(\tilde{R}^\prime \otimes \tilde{R}^\prime)
	\end{align*}

	From the definitions of $a$ and $\tilde{R} \tilde{Q} \tilde{R}$ above, 
	\begin{align*}
	\Gt(a) &= \Gt([I_m - T_1]^{-1} c_1) \\ 
		&= \Gt([I_m - T_1]^{-1}) (c_1 \otimes I_m) + \Gt(c_1) (I_m - T_1)^{-1})^\prime \\ 
		&= -\Gt(I_m - T_1) [(I_m - T_1)^{-1} \otimes (I_m - T_1)^{\prime-1} ](c_1 \otimes I_m) +  \Gt(c_1) (I_m - T_1)^{\prime-1} \\ 
		&= \Gt(T_1) [(I_m - T_1)^{-1} \otimes (I_m - T_1)^{\prime-1}] (c_1 \otimes I_m) +  \Gt(c_1) (I_m - T_1)^{\prime-1} \\
	\Gt(\tilde{R} \tilde{Q} \tilde{R}^\prime) &= \Gt(S \ \vecop(R_1 Q_1 R_1^\prime))\\
		&= \Gt(S) [\vecop(R_1 Q_1 R_1^\prime) \otimes I_{m^2}] + \Gt(\vecop(R_1 Q_1 R_1^\prime))(I_1 \otimes S^\prime) \\
		&= -\Gt(I_{m^2} - T_1 \otimes T_1)(S \otimes S^\prime) [\vecop(R_1 Q_1 R_1^\prime) \otimes I_{m^2}]\\ 
		&\quad + [\Gt(R_1)(Q_1 R_1^\prime \otimes I_m) N_m + \Gt(Q_1)(R_1^\prime \otimes R_1^\prime)] S^\prime \\
		&= \Gt(T_1 \otimes T_1)(S \otimes S^\prime) [\vecop(R_1 Q_1 R_1^\prime) \otimes I_{m^2}] \\
		&\quad + [\Gt(R_1)(Q_1 R_1^\prime \otimes I_m) N_m + \Gt(Q_1)(R_1^\prime \otimes R_1^\prime)] S^\prime
	\end{align*}
	where $S = (I_{m^2} - T_1 \otimes T_1)^{-1}$. Note that $\Gt(T_1 \otimes T_1)$ must be computed separately. For the diffuse filter, note that $\Gt(P_{*,1}) = \Gt(P_1)$ and $\Gt(P_{\infty,1}) = 0$.

\subsection{Univariate Treatment of Multivariate Series}

	For the univariate treatment of multivariate series, we need to find $\Gt(Z_t^*)$, $\Gt(d_t^*)$, and $\Gt(H_t^*)$ given $\Gt(Z_t)$, $\Gt(d_t)$, $\Gt(H_t)$, and $C_t$, the univariate factorization matrix. To do so, we  solve for $\Gt(H_t^*)$ and $\Gt(C_t)$, noting that elements of $\Gt(C_t)$ associated with the upper triangular elements of $C_t$ must be zero while elements of $\Gt(H_t^*)$ associated with off-diagonal elements of $H_t^*$ must be zero: 
	\begin{align*}
	\Gt(H_t) &= \Gt(C_t H_t^* C_t^\prime) \\
	&= \Gt(C_t)(H_t^* C_t^\prime \otimes I_p) N_p + \Gt(H_t^*)(C_t^\prime \otimes C_t^\prime) \\
	&= \begin{bmatrix} \Gt(C_t) & \Gt(H_t^*) \end{bmatrix} \begin{bmatrix} (H_t^* C_t^\prime \otimes I_p) N_p \\ C_t^\prime \otimes C_t^\prime \end{bmatrix} 
	= G_t W_t
	= \tilde{G}_t \tilde{W}_t
	\end{align*}
	where $\tilde{G}_t$ contains the nonzero columns of $G_t$ and $\tilde{W}_t$ contains the corresponding rows of $W_t$. The product $\Gt(H_t) \tilde{W}_t^+$ then provides an approximate solution for $\tilde{G}_t$ that can be reordered to solve for $\Gt(C_t)$ and $\Gt(H_t^*)$.

	Having solved for $\Gt(C_t)$, we can solve for the other gradients: 
	\begin{align*} 
	\Gt(Z_t^*) &= -\Gt(C_t)(C_t^{-1} \otimes C_t^{\prime-1})(Z_t \otimes I_p) + \Gt(Z_t)(I_m \otimes C_t^{\prime-1}) \\
	\Gt(d_t^*) &= -\Gt(C_t)(C_t^{-1} \otimes C_t^{\prime-1})(d_t \otimes I_p) + \Gt(d_t)C_t^{\prime-1}
	\end{align*}

\subsection{Parameter specification}

	The gradients of the state space parameters with respect to the reduced form parameters, $G_\psi(X)$, are  easily computed according to the derivatives of $\tau_{X_{i,j}}$. The gradients of the state space parameters with respect to the unrestricted parameters $\theta^U$ simply require the chain rule, $G_{\theta^U}(X) = G_{\theta^U}(\theta) \Gt(\psi) G_\psi(X) $. Note that in cases where $\psi \neq \theta$, $\Gt(\psi)$ must be provided by the user. With this provided, we can compute the analytic derivative of the state space likelihood with respect to the unconstrained parameter vector $\theta^U$.


\bibliography{kalman_filter_smoother} 
\bibliographystyle{unsrt}

\end{document}

